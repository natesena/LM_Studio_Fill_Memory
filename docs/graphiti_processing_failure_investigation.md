# Graphiti Processing Failure Investigation

## Issue Summary

**Date:** July 22, 2025  
**Status:** Root Cause Identified  
**Severity:** High - No episodes are being saved to Neo4j despite successful processing

## Problem Description

During batch processing, almost no new nodes were added to the graph despite Ollama logs showing successful chat completions. The issue appears to be in the Graphiti server's processing logic.

## Evidence

- Ollama logs show successful chat completions
- Graphiti logs show episodes being processed
- Neo4j database shows minimal new nodes added
- Python script successfully accesses queue status endpoint

## Root Cause Analysis

### **EXACT LOCATION OF THE ERROR**

**File:** `graphiti/graphiti_core/utils/maintenance/node_operations.py`  
**Function:** `resolve_extracted_nodes` (lines 223-325)  
**Specific Line:** Line 320

### **The Problem Code:**

```python
for resolution in node_resolutions:
    resolution_id: int = resolution.get('id', -1)
    duplicate_idx: int = resolution.get('duplicate_idx', -1)

    extracted_node = extracted_nodes[resolution_id]  # ‚Üê ERROR HERE

    resolved_node = (
        existing_nodes[duplicate_idx]  # ‚Üê AND HERE
        if 0 <= duplicate_idx < len(existing_nodes)
        else extracted_node
    )
```

### **Why This Happens:**

1.  **First Episode Processing**: When processing the first episode in a session, `previous_episodes` is an empty list `[]`
2.  **Empty Search Results**: Since there are no previous episodes, the search for existing nodes returns empty results
3.  **Empty existing_nodes List**: `existing_nodes = []` (empty list)
4.  **LLM Response Issue**: The LLM returns `node_resolutions` with `duplicate_idx` values that reference positions in the empty `existing_nodes` list
5.  **Index Out of Range**: When the code tries to access `existing_nodes[duplicate_idx]` where `duplicate_idx >= 0` but `existing_nodes` is empty, it throws `list index out of range`

### **Why Only First Episode Fails:**

- **First episode**: `previous_episodes = []` ‚Üí `existing_nodes = []` ‚Üí Error
- **Subsequent episodes**: `previous_episodes` contains the first episode ‚Üí `existing_nodes` has content ‚Üí No error

## Impact

- First episode in each processing session fails to save to Neo4j
- Subsequent episodes process successfully
- Results in incomplete data in the knowledge graph
- Batch processing appears to work but actually fails silently for the first file

## Investigation Plan

1. **Verify the Error**: Confirm the exact location and nature of the error
2. **Understand the Context**: Examine the `resolve_extracted_nodes` function and its dependencies
3. **Identify the Root Cause**: Determine why the LLM returns invalid indices
4. **Propose a Fix**: Implement defensive programming to handle empty lists
5. **Test the Fix**: Verify the solution works for both first and subsequent episodes

## Fix Implementation

### **Defensive Programming Added:**

```python
for resolution in node_resolutions:
    resolution_id: int = resolution.get('id', -1)
    duplicate_idx: int = resolution.get('duplicate_idx', -1)

    # Validate resolution_id bounds
    if resolution_id < 0 or resolution_id >= len(extracted_nodes):
        logger.warning(f"Invalid resolution_id {resolution_id} for extracted_nodes of length {len(extracted_nodes)}")
        continue

    extracted_node = extracted_nodes[resolution_id]

    # Safe access to existing_nodes with proper bounds checking
    resolved_node = (
        existing_nodes[duplicate_idx]
        if 0 <= duplicate_idx < len(existing_nodes)
        else extracted_node
    )

    resolved_node.name = resolution.get('name')

    resolved_nodes.append(resolved_node)
    uuid_map[extracted_node.uuid] = resolved_node.uuid

    additional_duplicates: list[int] = resolution.get('additional_duplicates', [])
    for idx in additional_duplicates:
        # Safe access to existing_nodes with bounds checking
        if idx < 0 or idx >= len(existing_nodes):
            logger.warning(f"Invalid additional_duplicate idx {idx} for existing_nodes of length {len(existing_nodes)}")
            continue

        existing_node = existing_nodes[idx]
        if existing_node == resolved_node:
            continue

        node_duplicates.append((resolved_node, existing_node))
```

## Queue Status Endpoint Investigation

### **Working Endpoint Confirmed:**

- **URL**: `http://localhost:8100/queue/status`
- **Server**: Separate FastAPI server running on port 8100 inside Docker container
- **Response**: `{"group_queues":{}}` (when queue is empty)
- **Status**: ‚úÖ Working correctly

### **CORS Issue RESOLVED:**

- **Problem**: Browser could not access `http://localhost:8100/queue/status` due to CORS policy
- **Error**: `Access to fetch at 'http://localhost:8100/queue/status' from origin 'http://localhost:8080' has been blocked by CORS policy`
- **Root Cause**: Cross-origin request from UI (port 8080) to queue status server (port 8100)

### **Solution Implemented:**

- **Approach**: Added OPTIONS endpoint to handle CORS preflight requests
- **File**: `graphiti/mcp_server/graphiti_mcp_server.py`
- **Changes**:
  - Added `@queue_status_app.options("/queue/status")` endpoint
  - Enhanced CORS middleware configuration
  - Added debug logging to queue status endpoint
- **Status**: ‚úÖ RESOLVED

### **Current State:**

1. ‚úÖ Queue status endpoint exists and works on port 8100
2. ‚úÖ Python script can access it successfully
3. ‚úÖ Browser can now access it (CORS resolved)
4. ‚úÖ UI can display queue status correctly
5. ‚úÖ All UI components showing proper data instead of errors

### **UI Status:**

- **Queue Status**: Shows "0 items" (working)
- **Active Workers**: Shows "0" (working)
- **System Health**: Shows "‚úÖ All Good" (working)
- **Queue Details**: No error messages (working)
- **Refresh Button**: Functional (working)

### **Next Steps:**

1. ‚úÖ CORS issue resolved
2. ‚úÖ UI functionality confirmed
3. üîÑ Continue with additional UI features (logging, node tracking, etc.)
